{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52de6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 16:32:49.475834: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-04 16:32:49.531502: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-04 16:32:50.497740: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Importation des librairies\n",
    "# -------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "# import de Input et Model\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553f37d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è GPU d√©tect√© : PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Configuration pour utiliser un seul GPU ou CPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(f\"üñ•Ô∏è GPU d√©tect√© : {physical_devices[0]}\")\n",
    "else:\n",
    "    print(\"üíª Utilisation du CPU\")\n",
    "\n",
    "# Style pour les visualisations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d014ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Chargement et pr√©paration des donn√©es\n",
    "# -------------------------------\n",
    "data = load_iris()\n",
    "X = data.data          # 4 caract√©ristiques (longueur/largeur p√©tales, s√©pales)\n",
    "y = data.target         # 3 classes de fleurs\n",
    "\n",
    "# Normalisation des donn√©es\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# D√©coupage en train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd3f558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/formation/alyra/s6/test-install-tensorflow/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762270371.095990   43463 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7115 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Cr√©ation du mod√®le ANN\n",
    "# -------------------------------\n",
    "model = Sequential([\n",
    "    Dense(8, activation='relu', input_shape=(4,)),   # Couche d'input +  couche cach√©e 1\n",
    "    Dense(8, activation='relu'),                     # Couche cach√©e 2\n",
    "    Dense(3, activation='softmax')                   # Couche de sortie (3 classes)\n",
    "])\n",
    "\n",
    "# Creation du mod√®le ANN en Seqeuential\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, activation='relu', input_shape=(4,)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Creation du mod√®le ANN\n",
    "def create_model():\n",
    "    x = Input(shape=(4,))\n",
    "    x1 = Dense(8, activation='relu')(x)\n",
    "    x2 = Dense(8, activation='relu')(x1)\n",
    "    output = Dense(3, activation='softmax')(x2)\n",
    "    return Model(inputs=x, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80116c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explication des Couches :\n",
    "\n",
    "# Input (4 entr√©es)\t: \n",
    "## R√¥le : Re√ßoit les 4 caract√©ristiques du dataset Iris\t\n",
    "## Pourquoi ce choix : Nombre fix√© par le nombre de features du dataset (longueur, largeur p√©tales/s√©pales)\n",
    "\n",
    "# 1re couche cach√©e (8 neurones)\n",
    "## R√¥le : Combine les entr√©es pour extraire des relations simples\n",
    "## Pourquoi ce choix : 8 neurones = petit mod√®le rapide √† entra√Æner, suffisant pour donn√©es simples\n",
    "\n",
    "# 2e couche cach√©e (8 neurones)\t\n",
    "## R√¥le : Apprend des relations plus abstraites (non lin√©aires)\n",
    "## Pourquoi ce choix : Ajouter de la profondeur permet d‚Äôapprendre des interactions plus complexes\n",
    "\n",
    "# Couche de sortie (3 neurones)\n",
    "## R√¥le : Donne les probabilit√©s pour chaque classe (Setosa, Versicolor, Virginica)\n",
    "## Pourquoi ce choix : Une sortie par classe + fonction softmax ‚Üí proba totale = 1\n",
    "\n",
    "# Id√©√© cl√© :\n",
    "## Une couche cach√©e apprend des motifs simples\n",
    "## Plusieurs couches encha√Æn√©es apprennent des repr√©sentations de plus en plus abstraites\n",
    "\n",
    "# Analogie :\n",
    "## C‚Äôest comme une √©quipe : \n",
    "## la 1 ≥·µâ couche ‚Äúobserve les d√©tails‚Äù,\n",
    "## la 2·µâ ‚Äúfait des associations‚Äù\n",
    "## la derni√®re ‚Äúprend la d√©cision finale‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703ac9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les fonctions d‚Äôactivation transforment la sortie de chaque neurone pour :\n",
    "## introduire de la non-lin√©arit√©,\n",
    "## permettre au mod√®le d‚Äôapprendre des relations complexes (non proportionnelles).\n",
    "\n",
    "# Avantages de ReLU\t‚Üí Pourquoi elle est souvent choisie\n",
    "## Simple et rapide √† calculer\t‚Üí permet un apprentissage plus rapide\n",
    "## Ne sature pas pour les valeurs positives\t‚Üí √©vite le probl√®me de ‚Äúvanishing gradient‚Äù\n",
    "## Donne des sorties nulles pour z < 0\t‚Üí favorise la parcimonie (neurones inactifs inutilement)\n",
    "\n",
    "# Analogie :\n",
    "## C‚Äôest un filtre intelligent : si le signal est fort ‚Üí il passe, sinon ‚Üí on l‚Äôignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a0ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√¥le                                                                | Pourquoi c‚Äôest le bon choix                                |\n",
    "# | ----------------------------------------------------------------- | ---------------------------------------------------------- |\n",
    "# | Convertit les sorties en probabilit√©s normalis√©es (somme = 1)     | ‚Üí Interpr√©table comme ‚Äúproba d‚Äôappartenir √† chaque classe‚Äù |\n",
    "# | Permet d‚Äôutiliser la cross-entropy comme fonction de co√ªt adapt√©e | ‚Üí Standard pour classification multi-classes               |\n",
    "\n",
    "# Analogie\n",
    "## C‚Äôest une course entre les classes : \n",
    "## chaque sortie repr√©sente la ‚Äúforce‚Äù d‚Äôune classe\n",
    "## et Softmax les transforme en pourcentages qui totalisent 100 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a5b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Compilation du mod√®le\n",
    "# -------------------------------\n",
    "model.compile(\n",
    "    optimizer='adam',             # Optimiseur : Adam = SGD am√©lior√©\n",
    "    loss='sparse_categorical_crossentropy',  # Fonction de co√ªt adapt√©e aux classes enti√®res\n",
    "    metrics=['accuracy']          # On suit la pr√©cision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee1977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 16:32:51.968438: I external/local_xla/xla/service/service.cc:163] XLA service 0x7ba47c005760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-04 16:32:51.968472: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 SUPER, Compute Capability 8.9\n",
      "2025-11-04 16:32:51.981722: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-04 16:32:52.050172: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "I0000 00:00:1762270372.617773   44341 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Entra√Ænement\n",
    "# -------------------------------\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "946eb052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√©cision sur le test : 0.93\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# √âvaluation\n",
    "# -------------------------------\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Pr√©cision sur le test : {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be74622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "Probabilit√©s : [[0.9895 0.0046 0.0059]]\n",
      "Classe pr√©dite : 0\n",
      "Fleur pr√©dite : Setosa\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Pr√©diction\n",
    "# -------------------------------\n",
    "sample = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "sample_scaled = scaler.transform(sample)\n",
    "\n",
    "pred = model.predict(sample_scaled)\n",
    "print(\"Probabilit√©s :\", np.round(pred,4))\n",
    "print(\"Classe pr√©dite :\", np.argmax(pred))\n",
    "\n",
    "if np.argmax(pred) == 0:\n",
    "    print(\"Fleur pr√©dite : Setosa\")\n",
    "elif np.argmax(pred) == 1:\n",
    "    print(\"Fleur pr√©dite : Versicolor\")\n",
    "else:\n",
    "    print(\"Fleur pr√©dite : Virginica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23422cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
