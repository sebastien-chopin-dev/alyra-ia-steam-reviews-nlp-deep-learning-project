{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c115ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Import des librairies\n",
    "# -------------------------------\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2784bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Chargement et préparation des données\n",
    "# -------------------------------\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Redimensionnement : (28x28) → (28x28x1)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Encodage one-hot des labels (0–9)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b823b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/formation/alyra/s6/test-install-tensorflow/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762270345.433003   39134 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9515 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Création du modèle CNN\n",
    "# -------------------------------\n",
    "model = Sequential([\n",
    "    # Couches convolutionnelles = extraction de motifs\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), \n",
    "    MaxPooling2D((2, 2)),  # Réduction de dimension\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),  # Aplatit les cartes de caractéristiques\n",
    "    Dense(64, activation='relu'),  # Couches fully connected\n",
    "    Dense(10, activation='softmax')  # Sortie à 10 classes\n",
    "])\n",
    "\n",
    "def create_model():\n",
    "    x = Sequential()\n",
    "    x.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    x.add(MaxPooling2D((2, 2)))\n",
    "    x.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    x.add(MaxPooling2D((2, 2)))\n",
    "    x.add(Flatten())\n",
    "    x.add(Dense(64, activation='relu'))\n",
    "    x.add(Dense(10, activation='softmax'))\n",
    "    return x\n",
    "\n",
    "\n",
    "# Fonction de création du modèle CNN avec l'API fonctionnelle\n",
    "def create_model():\n",
    "    x = Input(shape=(28, 28, 1))\n",
    "    x1 = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x2 = MaxPooling2D((2, 2))(x1)\n",
    "    x3 = Conv2D(64, (3, 3), activation='relu')(x2)\n",
    "    x4 = MaxPooling2D((2, 2))(x3)\n",
    "    x5 = Flatten()(x4)\n",
    "    x6 = Dense(64, activation='relu')(x5)\n",
    "    output = Dense(10, activation='softmax')(x6)\n",
    "    return Model(inputs=x, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754de27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Compilation\n",
    "# -------------------------------\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8fa1c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 16:32:27.775227: I external/local_xla/xla/service/service.cc:163] XLA service 0x7a807400b7c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-04 16:32:27.775258: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 SUPER, Compute Capability 8.9\n",
      "2025-11-04 16:32:27.793326: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-04 16:32:27.892387: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "2025-11-04 16:32:27.912362: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-04 16:32:28.656208: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_533', 420 bytes spill stores, 420 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 76/844\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 1.4170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762270349.974616   43710 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m820/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.4254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 16:32:31.751837: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-04 16:32:31.751882: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-04 16:32:32.168105: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_444', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-11-04 16:32:32.296282: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_444', 380 bytes spill stores, 380 bytes spill loads\n",
      "\n",
      "2025-11-04 16:32:32.304500: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_444', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-11-04 16:32:32.500720: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_533', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.1848 - val_accuracy: 0.9810 - val_loss: 0.0662\n",
      "Epoch 2/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -220us/step - accuracy: 0.9812 - loss: 0.0599 - val_accuracy: 0.9857 - val_loss: 0.0463\n",
      "Epoch 3/3\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0418 - val_accuracy: 0.9888 - val_loss: 0.0381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a81bcf3f3b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Entraînement\n",
    "# -------------------------------\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41567a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur MNIST : 0.99\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Évaluation\n",
    "# -------------------------------\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Précision sur MNIST : {test_acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
