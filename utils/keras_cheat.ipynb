{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a776204",
   "metadata": {},
   "source": [
    "Interface keras et manipulation des tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88bd48b",
   "metadata": {},
   "source": [
    "Organisation modulaire de Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda498fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules principaux\n",
    "keras.layers # Couches (Dense, Conv2D, LSTM, etc.)\n",
    "keras.models # Modèles (Sequential, Model)\n",
    "keras.optimizers  # Optimiseurs (Adam, SGD, RMSprop)\n",
    "keras.losses # Fonctions de perte\n",
    "keras.metrics # Métriques d'évaluation\n",
    "keras.callbacks  # Callbacks (EarlyStopping, ModelCheckpoint)\n",
    "keras.datasets  # Datasets intégrés\n",
    "keras.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1021c8",
   "metadata": {},
   "source": [
    " Un tenseur est un tableau multidimensionnel typé avec des métadonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c33c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (), Rank: 0\n",
      "Shape: (4,), Rank: 1\n",
      "Shape: (3, 2), Rank: 2\n",
      "Shape: (2, 2, 2), Rank: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761660709.380587   77825 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9515 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Scalaire (0D) - un nombre\n",
    "scalar = tf.constant(42)\n",
    "print(f\"Shape: {scalar.shape}, Rank: {tf.rank(scalar)}\")\n",
    "\n",
    "# Vecteur (1D) - liste de nombres\n",
    "vector = tf.constant([1, 2, 3, 4])\n",
    "print(f\"Shape: {vector.shape}, Rank: {tf.rank(vector)}\")\n",
    "\n",
    "# Matrice (2D) - tableau de tableaux\n",
    "matrix = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "print(f\"Shape: {matrix.shape}, Rank: {tf.rank(matrix)}\")\n",
    "\n",
    "# Tenseur 3D - pile de matrices\n",
    "tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(f\"Shape: {tensor_3d.shape}, Rank: {tf.rank(tensor_3d)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1cf8a",
   "metadata": {},
   "source": [
    " Méthodes de création courantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692afcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenseurs constants\n",
    "zeros = tf.zeros(shape=(3, 4))                    # Matrice de zéros [[0., 0., 0., 0.],[0., 0., 0., 0.],[0., 0., 0., 0.]]\n",
    "ones = tf.ones(shape=(2, 3), dtype=tf.float32)    # Matrice de uns [[1., 1., 1.],[1., 1., 1.]]\n",
    "fill = tf.fill(dims=(2, 2), value=7)              # Rempli avec une valeur [[7, 7],[7, 7]]\n",
    "\n",
    "# Tenseurs aléatoires\n",
    "normal = tf.random.normal(shape=(100, 10), mean=0.0, stddev=1.0) # [[-8.10366809e-01,  1.38839972e+00, -1.99497747e+00 ...]]\n",
    "uniform = tf.random.uniform(shape=(50, 20), minval=0, maxval=1)  # [[0.85373425, 0.5935111 , 0.19142246, 0.74564636...]]\n",
    "\n",
    "# Séquences\n",
    "range_tensor = tf.range(start=0, limit=10, delta=2)       # [0, 2, 4, 6, 8] attention n'inclus pas la limit (ici 10)\n",
    "linspace = tf.linspace(start=0.0, stop=1.0, num=5)        # [0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "# Tenseurs variables (modifiables)\n",
    "variable = tf.Variable(tf.random.normal((10, 10)))\n",
    "print(f\"Trainable: {variable.trainable}\")   # True par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738473b",
   "metadata": {},
   "source": [
    "Création de tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75b86e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Spécification du type et device\n",
    "\n",
    "\n",
    "tensor_int = tf.constant(value=[1, 2, 3], dtype=tf.int64) # Type explicite\n",
    "tensor_float = tf.cast(tensor_int, tf.float32)  # Conversion\n",
    "\n",
    "# Device placement\n",
    "with tf.device('/CPU:0'):\n",
    "    cpu_tensor = tf.ones((1000, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63deca25",
   "metadata": {},
   "source": [
    "Manipulation des formes (Reshaping)\n",
    "- Le nombre total d'éléments doit rester constant-1\n",
    "- -1 dans reshape = \"calcule automatiquement cette dimension\"\n",
    "- Les opérations créent de nouveaux tenseurs (immutabilité)\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'éléments: 6\n",
      "Compatible reshape: True\n"
     ]
    }
   ],
   "source": [
    "# Tenseur initial\n",
    "original = tf.constant([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
    "\n",
    "# Reshape - change les dimensions mais garde le nombre d'éléments\n",
    "reshaped = tf.reshape(original, (3, 2))       # Shape: (3, 2)\n",
    "flattened = tf.reshape(original, (-1,))       # Shape: (6,) - vecteur\n",
    "      \n",
    "# Transpose - inverse les axes\n",
    "transposed = tf.transpose(original)           # Shape: (3, 2)\n",
    "        \n",
    "# Expand/squeeze dimensions\n",
    "expanded = tf.expand_dims(original, axis=0)   # Shape: (1, 2, 3)   \n",
    "squeezed = tf.squeeze(expanded)               # Shape: (2, 3)\n",
    "         \n",
    "# Vérification de compatibilité\n",
    "print(f\"Nombre d'éléments: {tf.size(original).numpy()}\")\n",
    "print(f\"Compatible reshape: {tf.size(original) == tf.size(reshaped)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06175e",
   "metadata": {},
   "source": [
    "Opérations mathématiques sur tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e742c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "b = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
    "\n",
    "# Arithmétique élément par élément\n",
    "addition = a + b        # ou tf.add(a, b)\n",
    "subtraction = a - b     # ou tf.subtract(a, b)\n",
    "multiplication = a * b  # ou tf.multiply(a, b) - ATTENTION: pas matriciel\n",
    "division = a / b        # ou tf.divide(a, b)\n",
    "\n",
    "# Fonctions mathématiques\n",
    "sqrt_a = tf.sqrt(a)\n",
    "exp_a = tf.exp(a)\n",
    "log_a = tf.math.log(a)\n",
    "abs_a = tf.abs(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d64d4d",
   "metadata": {},
   "source": [
    "Indexation et slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[[1, 2], [3, 4]], \n",
    "                      [[5, 6], [7, 8]]])  # Shape: (2, 2, 2)\n",
    "\n",
    "# Indexation simple\n",
    "\n",
    "element = tensor[0, 0, 0]  # Accès à un élément: 1\n",
    "element = tensor[0, 0, 1]  # Accès à un élément: 2\n",
    "element = tensor[0, 1, 0]  # Accès à un élément: 3\n",
    "element = tensor[0, 1, 1]  # Accès à un élément: 4\n",
    "\n",
    "element = tensor[1, 0, 0]  # Accès à un élément: 5\n",
    "element = tensor[1, 0, 1]  # Accès à un élément: 6\n",
    "element = tensor[1, 1, 0]  # Accès à un élément: 7\n",
    "element = tensor[1, 1, 1]  # Accès à un élément: 8\n",
    "\n",
    "# Slicing (comme NumPy)\n",
    "slice_1 = tensor[0, :, :]  # Première \"page\": [[1, 2], [3, 4]]\n",
    "slice_2 = tensor[:, 0, :]  # Première ligne de chaque page: [[1, 2], [5, 6]]\n",
    "slice_3 = tensor[..., 1]   # Dernière colonne: [[2, 4], [6, 8]]\n",
    "\n",
    "# Slicing avec step\n",
    "every_other = tensor[::2]  # Un élément sur deux\n",
    "\n",
    "# Indexation conditionnelle\n",
    "mask = tensor > 4\n",
    "filtered = tf.boolean_mask(tensor, mask)  # Éléments > 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e22aee",
   "metadata": {},
   "source": [
    " Conversions bidirectionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6cbb516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type original: <class 'numpy.ndarray'>\n",
      "Type TF: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Type converti: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# NumPy vers TensorFlow\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n",
    "tf_tensor = tf.constant(numpy_array)\n",
    "\n",
    "# ou automatiquement:\n",
    "tf_tensor_auto = tf.add(numpy_array, 1)\n",
    "\n",
    "# TensorFlow vers NumPy\n",
    "tf_tensor = tf.constant([[1, 2], [3, 4]])\n",
    "numpy_result = tf_tensor.numpy()  # Méthode .numpy()\n",
    "\n",
    "print(f\"Type original: {type(numpy_array)}\")\n",
    "print(f\"Type TF: {type(tf_tensor)}\")\n",
    "print(f\"Type converti: {type(numpy_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90078a",
   "metadata": {},
   "source": [
    " Interopérabilité automatique\n",
    "\n",
    " Attention aux copies mémoire\n",
    "\n",
    " - tf.constant(numpy_array) → Copie les données\n",
    " - .numpy() → Copie depuis GPU vers CPU si nécessaire\n",
    " - Variables partagent parfois la mémoire avec NumPy (CPU uniquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow accepte automatiquement les arrays NumPy\n",
    "np_data = np.random.normal(0, 1, (100, 10))\n",
    "tf_result = tf.reduce_mean(np_data)  # Fonctionne directement\n",
    "\n",
    "# Les opérations mixtes fonctionnent\n",
    "mixed = tf.add(np_data, tf.constant(5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b08934f",
   "metadata": {},
   "source": [
    "Types de données courants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da43fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types numériques principaux\n",
    "float_types = [tf.float16, tf.float32, tf.float64]   # demi, simple, double précision\n",
    "int_types = [tf.int8, tf.int16, tf.int32, tf.int64]  # entiers signés\n",
    "uint_types = [tf.uint8, tf.uint16]                   # entiers non signés\n",
    "bool_type = tf.bool                                  # booléen\n",
    "\n",
    "# Création avec type spécifique\n",
    "tensor_f16 = tf.constant([1.0, 2.0], dtype=tf.float16)  # Plus rapide, moins précis\n",
    "tensor_f32 = tf.constant([1.0, 2.0], dtype=tf.float32)  # Standard DL\n",
    "tensor_f64 = tf.constant([1.0, 2.0], dtype=tf.float64)  # Plus précis, plus lent\n",
    "\n",
    "# Conversion de types\n",
    "converted = tf.cast(tensor_f64, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35264d",
   "metadata": {},
   "source": [
    " Bonnes pratiques performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af700d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préférer float32 pour le Deep Learning (compromise vitesse/précision)\n",
    "weights = tf.Variable(tf.random.normal((1000, 1000), dtype=tf.float32))\n",
    "\n",
    "# Éviter les conversions répétées\n",
    "\n",
    "# ❌Mauvais\n",
    "for i in range(100):\n",
    "    result = tf.cast(weights, tf.float64)  # Conversion à chaque itération\n",
    "    \n",
    "# ✅Bon  \n",
    "weights_f64 = tf.cast(weights, tf.float64)  # Une seule conversion\n",
    "for i in range(100):\n",
    "    result = weights_f64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d51c4ce",
   "metadata": {},
   "source": [
    " Cas concret : batch d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84143a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (32, 224, 224, 3)\n",
      "Labels shape: (32,)\n",
      "Memory usage: ~18.4 MB\n",
      "One-hot shape: (32, 10)\n",
      "Images normalized - Mean: -0.000\n",
      "Images normalized - Std: 1.000\n",
      "One-hot sum per sample: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Simulation d'un batch d'images RGB 224x224\n",
    "batch_size = 32\n",
    "height, width, channels = 224, 224, 3 #(224px X 224px) (r,g,b)\n",
    "\n",
    "# Création d'un batch aléatoire\n",
    "images_batch = tf.random.normal((batch_size, height, width, channels))\n",
    "labels_batch = tf.random.uniform((batch_size,), maxval=10, dtype=tf.int32)\n",
    "\n",
    "print(f\"Images shape: {images_batch.shape}\")  # (32, 224, 224, 3)\n",
    "print(f\"Labels shape: {labels_batch.shape}\")  # (32,)\n",
    "print(f\"Memory usage: ~{images_batch.numpy().nbytes / 1024**2:.1f} MB\")\n",
    "\n",
    "# One-hot encoding des labels\n",
    "num_classes = 10\n",
    "labels_onehot = tf.one_hot(labels_batch, num_classes)\n",
    "print(f\"One-hot shape: {labels_onehot.shape}\")  # (32, 10)\n",
    "\n",
    "# Normalisation (preprocessing typique)\n",
    "normalized_images = (images_batch - tf.reduce_mean(images_batch)) / tf.math.reduce_std(images_batch)\n",
    "\n",
    "# Vérifications\n",
    "print(f\"Images normalized - Mean: {tf.reduce_mean(normalized_images):.3f}\")\n",
    "print(f\"Images normalized - Std: {tf.math.reduce_std(normalized_images):.3f}\")\n",
    "print(f\"One-hot sum per sample: {tf.reduce_sum(labels_onehot, axis=1)}\")  # Doit être [1,1,1,...]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
